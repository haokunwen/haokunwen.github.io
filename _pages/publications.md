---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

## Preprints
---

<details>
  <summary>FineCIR: Explicit Parsing of Fine-Grained Modification Semantics for Composed Image Retrieval</summary>
  <pre><code>@article{li2025finecir,
  title={FineCIR: Explicit Parsing of Fine-Grained Modification Semantics for Composed Image Retrieval},
  author={Li, Zixu and Fu, Zhiheng and Hu, Yupeng and Chen, Zhiwei and Wen, Haokun and Nie, Liqiang},
  journal={arXiv preprint arXiv:2503.21309},
  year={2025}
}</code></pre>
</details>
<div class="pub-content">
  Zixu Li, Zhiheng Fu, Yupeng Hu, Zhiwei Chen, <b>Haokun Wen</b>, and Liqiang Nie.<br>
  ArXiv preprint.
  <a href="https://arxiv.org/pdf/2503.21309" style="margin-left: 8px;"><img src="https://img.shields.io/badge/Paper-PDF-b31b1b"></a>
</div>

<details>
  <summary>Dual Knowledge-Enhanced Two-Stage Reasoner for Multimodal Dialog Systems</summary>
  <pre><code>@article{chen2025dual,
  title={Dual Knowledge-Enhanced Two-Stage Reasoner for Multimodal Dialog Systems},
  author={Chen, Xiaolin and Song, Xuemeng and Wen, Haokun and Guan, Weili and Zhao, Xiangyu and Nie, Liqiang},
  journal={arXiv preprint arXiv:2509.07817},
  year={2025}
}</code></pre>
</details>
<div class="pub-content">
  Xiaolin Chen, Xuemeng Song, <b>Haokun Wen</b>, Weili Guan, Xiangyu Zhao, and Liqiang Nie.<br>
  ArXiv preprint.
  <a href="https://arxiv.org/abs/2509.07817v1" style="margin-left: 8px;"><img src="https://img.shields.io/badge/Paper-PDF-b31b1b"></a>
</div>


## 2026
---

<details>
  <summary>D2MoRA: Diversity-Regulated Asymmetric MoE-LoRA Decomposition for Efficient Multi-Task Adaptation</summary>
  <pre><code> </code></pre>
</details>
<div class="pub-content">
  Jianhui Zuo, Xuemeng Song, <b>Haokun Wen</b>, Meng Liu, Yupeng Hu, Jiuru Wang, and Liqiang Nie. <br>
  AAAI 2026.
</div>


    
## 2025
---
  - **Multi-modal Recommendation with Joint Content and Interaction Augmentation**     
    Jiajie Deng, **Haokun Wen**, Xiao Han, Xuemeng Song, and Xiangyu Zhao.     
    In MMAsia 2025.     
  - **Spatial Understanding from Videos: Structured Prompts Meet Simulation Data**      
    Haoyu Zhang, Meng Liu, Zaijing Li, **Haokun Wen**, Weili Guan, Yaowei Wang, and Liqiang Nie.    
    In NeurIPS 2025. [![Paper](https://img.shields.io/badge/Paper-PDF-b31b1b)](https://arxiv.org/pdf/2506.03642?)    
  - **A Comprehensive Survey on Composed Image Retrieval**     
    Xuemeng Song, Haoqiang Lin, **Haokun Wen**, Bohan Hou, Mingzhu Xu, and Liqiang Nie.    
    ACM TOIS 2025. [![Paper](https://img.shields.io/badge/Paper-PDF-b31b1b)](https://arxiv.org/pdf/2502.18495)    
  - **ENCODER: Entity Mining and Modification Relation Binding for Composed Image Retrieval**     
    Zixu Li, Zhiwei Chen, **Haokun Wen**, Zhiheng Fu, Yupeng Hu, and Weili Guan.        
    In AAAI 2025. [![Paper](https://img.shields.io/badge/Paper-PDF-b31b1b)](https://ojs.aaai.org/index.php/AAAI/article/view/32541) [![Code](https://img.shields.io/badge/Code-GitHub-181717)](https://sdu-l.github.io/ENCODER.github.io/)         
  - **FiRE: Enhancing MLLMs with Fine-Grained Context Learning for Complex Image Retrieval**    
    Bohan Hou, Haoqiang Lin, Xuemeng Song, **Haokun Wen**, Meng Liu, Yupeng Hu, and Xiangyu Zhao.    
    In SIGIR 2025. [![Paper](https://img.shields.io/badge/Paper-PDF-b31b1b)](https://dl.acm.org/doi/10.1145/3726302.3729979)       
  - **Pseudo-triplet Guided Few-shot Composed Image Retrieval**      
    Bohan Hou, Haoqiang Lin, **Haokun Wen**, Meng Liu, and Xuemeng Song.    
    In IJCNN 2025. [![Paper](https://img.shields.io/badge/Paper-PDF-b31b1b)](https://arxiv.org/abs/2407.06001)    
  - **HUD: Hierarchical Uncertainty-Aware Disambiguation Network for Composed Video Retrieval**    
    Zhiwei Chen, Yupeng Hu, Zixu Li, Zhiheng Fu, **Haokun Wen**, and Weili Guan.    
    In ACM MM 2025. [![Paper](https://img.shields.io/badge/Paper-PDF-b31b1b)](https://dl.acm.org/doi/10.1145/3746027.3755445)        

**2024**  
  - **Simple but Effective Raw-Data Level Multimodal Fusion for Composed Image Retrieval**   
    **Haokun Wen**, Xuemeng Song, Xiaolin Chen, Yinwei Wei, Liqiang Nie, and Tat-Seng Chua.      
    In ACM SIGIR 2024 (full paper). [![Paper](https://img.shields.io/badge/Paper-PDF-b31b1b)](https://arxiv.org/abs/2404.15875) [[Code]](https://github.com/haokunwen/DQU-CIR) [![Slides](https://img.shields.io/badge/Slides-PDF-0056b3)](http://haokunwen.github.io/files/SIGIR24_DQU-CIR.pdf)


<!-- 第一部分：标题和隐藏的 BibTeX (注意 </details> 的位置) -->
<details>
  <summary style="cursor: pointer; font-weight: bold; outline: none;">Simple but Effective Raw-Data Level Multimodal Fusion for Composed Image Retrieval</summary>
  <pre style="background: #f6f8fa; border: 1px solid #ddd; padding: 10px; margin-top: 5px; border-radius: 5px; overflow-x: auto;"><code>@article{wen2024simple,
  title={Simple but Effective Raw-Data Level Multimodal Fusion for Composed Image Retrieval},
  author={Wen, Haokun and Song, Xuemeng and Chen, Xiaolin and Wei, Yinwei and Nie, Liqiang and Chua, Tat-Seng},
  journal={ACM SIGIR},
  year={2024}
}</code></pre>
</details>

<!-- 第二部分：作者和链接 (放在外面，并且用 div 包裹以防缩进错误) -->
<div style="margin-top: 5px; margin-bottom: 20px;">
  <b>Haokun Wen</b>, Xuemeng Song, Xiaolin Chen, Yinwei Wei, Liqiang Nie, and Tat-Seng Chua.<br>
  In ACM SIGIR 2024 (full paper). 
  <!-- 这里的链接保持在一行 -->
  <a href="https://arxiv.org/abs/2404.15875"><img src="https://img.shields.io/badge/Paper-PDF-b31b1b"></a>
  <a href="https://github.com/haokunwen/DQU-CIR"><img src="https://img.shields.io/badge/Code-GitHub-181717"></a>
  <a href="http://haokunwen.github.io/files/SIGIR24_DQU-CIR.pdf"><img src="https://img.shields.io/badge/Slides-PDF-0056b3"></a>
</div>

<!-- 1. 这里修改了 summary 的样式: color:#000 (纯黑), font-size:1.15em (加大) -->
<details>
  <summary style="cursor: pointer; font-weight: bold; outline: none; color: #000000; font-size: 1.15em; line-height: 1.4;">Simple but Effective Raw-Data Level Multimodal Fusion for Composed Image Retrieval</summary>
  
  <!-- BibTeX 代码区域 -->
  <pre style="background: #f6f8fa; border: 1px solid #ddd; padding: 10px; margin-top: 5px; border-radius: 5px; overflow-x: auto;"><code>@article{wen2024simple,
  title={Simple but Effective Raw-Data Level Multimodal Fusion for Composed Image Retrieval},
  author={Wen, Haokun and Song, Xuemeng and Chen, Xiaolin and Wei, Yinwei and Nie, Liqiang and Chua, Tat-Seng},
  journal={ACM SIGIR},
  year={2024}
}</code></pre>
</details>

<!-- 2. 作者和链接区域 -->
<div style="margin-top: 5px; margin-bottom: 25px; font-size: 1em; color: #333;">
  <b>Haokun Wen</b>, Xuemeng Song, Xiaolin Chen, Yinwei Wei, Liqiang Nie, and Tat-Seng Chua.<br>
  <span style="font-style: italic;">In ACM SIGIR 2024 (full paper).</span>
  
  <!-- 链接徽章 -->
  <a href="https://arxiv.org/abs/2404.15875" style="margin-left: 5px;"><img src="https://img.shields.io/badge/Paper-PDF-b31b1b" style="vertical-align: middle;"></a>
  <a href="https://github.com/haokunwen/DQU-CIR"><img src="https://img.shields.io/badge/Code-GitHub-181717" style="vertical-align: middle;"></a>
  <a href="http://haokunwen.github.io/files/SIGIR24_DQU-CIR.pdf"><img src="https://img.shields.io/badge/Slides-PDF-0056b3" style="vertical-align: middle;"></a>
</div>

<!-- 1. 题目区域: margin-bottom: 0 (去除底部空隙) -->
<details style="margin-bottom: 0px;">
  <summary style="cursor: pointer; font-weight: bold; outline: none; color: #000; font-size: 1.15em; line-height: 1.2;">Simple but Effective Raw-Data Level Multimodal Fusion for Composed Image Retrieval</summary>
  
  <!-- BibTeX 代码框 (保持不变) -->
  <pre style="background: #f6f8fa; border: 1px solid #ddd; padding: 10px; margin-top: 5px; margin-bottom: 10px; border-radius: 5px; overflow-x: auto;"><code>@article{wen2024simple,
  title={Simple but Effective Raw-Data Level Multimodal Fusion for Composed Image Retrieval},
  author={Wen, Haokun and Song, Xuemeng and Chen, Xiaolin and Wei, Yinwei and Nie, Liqiang and Chua, Tat-Seng},
  journal={ACM SIGIR},
  year={2024}
}</code></pre>
</details>

<!-- 2. 作者区域: margin-top: 2px (只留极小的缝隙) -->
<div style="margin-top: 2px; margin-bottom: 30px; font-size: 1em; color: #333; line-height: 1.5;">
  <b>Haokun Wen</b>, Xuemeng Song, Xiaolin Chen, Yinwei Wei, Liqiang Nie, and Tat-Seng Chua.<br>
  <span style="font-style: italic;">In ACM SIGIR 2024 (full paper).</span>
  
  <a href="https://arxiv.org/abs/2404.15875" style="margin-left: 5px;"><img src="https://img.shields.io/badge/Paper-PDF-b31b1b" style="vertical-align: middle;"></a>
  <a href="https://github.com/haokunwen/DQU-CIR"><img src="https://img.shields.io/badge/Code-GitHub-181717" style="vertical-align: middle;"></a>
</div>

<details>
  <summary>Simple but Effective Raw-Data Level Multimodal Fusion for Composed Image Retrieval</summary>
  <pre><code>@article{wen2024simple,
  ... (BibTeX内容) ...
}</code></pre>
</details>

<!-- 下面紧接作者，div 也可以简化样式 -->
<div style="margin-top: 2px; margin-bottom: 25px;">
  <b>Haokun Wen</b>, Xuemeng Song... (后续内容)
</div>

  - **Self-Training Boosted Multi-Factor Matching Network for Composed Image Retrieval**    
    **Haokun Wen**, Xuemeng Song, Jianhua Yin, Jianlong Wu, Weili Guan, and Liqiang Nie.   
    IEEE TPAMI, 2024. [![Paper](https://img.shields.io/badge/Paper-PDF-b31b1b)](https://ieeexplore.ieee.org/abstract/document/10373096) [[Code]](https://anosite.wixsite.com/limn) [[BibTex]](https://dblp.org/rec/journals/pami/WenSYWGN24.html?view=bibtex)     

  - **Fine-Grained Textual Inversion Network for Zero-Shot Composed Image Retrieval**   
    Haoqiang Lin, **Haokun Wen**, Xuemeng Song, Meng Liu, Yupeng Hu, and Liqiang Nie.      
    In ACM SIGIR 2024 (full paper).  [![Paper](https://img.shields.io/badge/Paper-PDF-b31b1b)](https://dl.acm.org/doi/10.1145/3626772.3657831) [[Code]](https://github.com/ZiChao111/FTI4CIR) [[BibTex]](https://dblp.org/rec/conf/sigir/LinWS0HN24.html?view=bibtex)  

  - **Differential-Perceptive and Retrieval-Augmented MLLM for Change Captioning**  
    Xian Zhang, **Haokun Wen**, Jianlong Wu, Pengda Qin, Hui Xue, and Liqiang Nie.  
    In ACM MM 2024 (full paper). [![Paper](https://img.shields.io/badge/Paper-PDF-b31b1b)](https://openreview.net/attachment?id=eiGs5VCsYM&name=pdf) [[Code]](https://github.com/xianzhangzx/FINER-MLLM)

  - **Interactive Garment Recommendation with User in the Loop**    
    Federico Becattini, Xiaolin Chen, Andrea Puccia, **Haokun Wen**, Xuemeng Song, Liqiang Nie, and Alberto Del Bimbo.  
    ACM ToMM 2024. [![Paper](https://img.shields.io/badge/Paper-PDF-b31b1b)](https://arxiv.org/abs/2402.11627)  

**2023**  
  - **Target-Guided Composed Image Retrieval**   
    **Haokun Wen**, Xian Zhang, Xuemeng Song, Yinwei Wei, and Liqiang Nie.    
    In ACM MM 2023 (full paper). [![Paper](https://img.shields.io/badge/Paper-PDF-b31b1b)](https://arxiv.org/pdf/2309.01366.pdf) [[Code]](https://anosite.wixsite.com/tg-cir) [[Slides]](http://haokunwen.github.io/files/mm23-TG-CIR.pdf) [[BibTex]](https://dblp.org/rec/conf/mm/WenZSWN23.html?view=bibtex)    

  - **Finetuning Language Models for Multimodal Question Answering**  
    Xin Zhang$^1$, Wen Xie$^1$, Ziqi Dai$^1$, Jun Rao, **Haokun Wen**, Xuan Luo, Meishan Zhang, and Min Zhang.  
    In ACM MM 2023 (grand challenge). [![Paper](https://img.shields.io/badge/Paper-PDF-b31b1b)](http://haokunwen.github.io/files/acmmm2023_grandchallenge.pdf) [[BibTex]](https://dblp.org/rec/conf/mm/ZhangXDRWLZZ23.html?view=bibtex)    
    Ranked 1st in both Chinese and English tracks of the [VTQA 2023](https://visual-text-QA.github.io/).  

  - **Egocentric Early Action Prediction via Multimodal Transformer-Based Dual Action Prediction**    
    Weili Guan, Xuemeng Song, Kejie Wang, **Haokun Wen**, Hongda Ni, Yaowei Wang, and Xiaojun Chang.   
    IEEE TCSVT, 2023. [![Paper](https://img.shields.io/badge/Paper-PDF-b31b1b)](http://haokunwen.github.io/files/tcsvt2023.pdf) [[Code]](https://trace729.wixsite.com/trace) [[BibTex]](https://dblp.org/rec/journals/tcsv/GuanSWWNWC23.html?view=bibtex)    

**2022**
  - **Personalized Fashion Compatibility Modeling via Metapath-guided Heterogeneous Graph Learning**  
    Weili Guan, Fangkai Jiao, Xuemeng Song, **Haokun Wen**, Chung-Hsing Yeh, and Xiaojun Chang.    
    In ACM SIGIR 2022 (full paper). [![Paper](https://img.shields.io/badge/Paper-PDF-b31b1b)](http://haokunwen.github.io/files/acmsigir2022.pdf) [[Code]](https://anosite.wixsite.com/pfcm) [[BibTex]](https://dblp.org/rec/conf/sigir/GuanJSWYC22.html?view=bibtex)     

  - **Partially Supervised Compatibility Modeling**  
    Weili Guan, **Haokun Wen**, Xuemeng Song, Chun Wang, Chung-Hsing Yeh, Xiaojun Chang, and Liqiang Nie.  
    IEEE TIP, 2022. [![Paper](https://img.shields.io/badge/Paper-PDF-b31b1b)](http://haokunwen.github.io/files/tip2022.pdf) [[Code]](https://site2750.wixsite.com/ps-ocm) [[BibTex]](https://dblp.org/rec/journals/tip/GuanWSWYCN22.html?view=bibtex)  

**2021**
  - **Comprehensive Linguistic-Visual Composition Network for Image Retrieval**  
    **Haokun Wen**, Xuemeng Song, Xin Yang, Yibing Zhan, and Liqiang Nie.  
    In ACM SIGIR 2021 (full paper). [![Paper](https://img.shields.io/badge/Paper-PDF-b31b1b)](http://haokunwen.github.io/files/acmsigir2021.pdf) [[Code]](https://site2750.wixsite.com/clvcnet) [[BibTex]](https://dblp.org/rec/conf/sigir/WenSYZN21.html?view=bibtex)  

  - **Multimodal Compatibility Modeling via Exploring the Consistent and Complementary Correlations**  
    Weili Guan, **Haokun Wen**, Xuemeng Song, Chung-Hsing Yeh, Xiaojun Chang, and Liqiang Nie.  
    In ACM MM 2021 (full paper). [![Paper](https://img.shields.io/badge/Paper-PDF-b31b1b)](http://haokunwen.github.io/files/acmmm2021.pdf) [[Code]](https://site2750.wixsite.com/mmocm) [[BibTex]](https://dblp.org/rec/conf/mm/GuanWSYCN21.html?view=bibtex)  

  - **Attribute-wise Explainable Fashion Compatibility Modeling**  
    Xin Yang, Xuemeng Song, Fuli Feng, **Haokun Wen**, Ling-Yu Duan, and Liqiang Nie.  
    ACM ToMM, 2021. [![Paper](https://img.shields.io/badge/Paper-PDF-b31b1b)](http://haokunwen.github.io/files/acmtomm2021.pdf) [[Code]](https://joeyangbuer.wixsite.com/exfcm) [[BibTex]](https://dblp.org/rec/journals/tomccap/YangSFWDN21.html?view=bibtex)    

**2020**
  - **Generative Attribute Manipulation Scheme for Flexible Fashion Search**  
    Xin Yang, Xuemeng Song, Xianjing Han, **Haokun Wen**, Jie Nie, and Liqiang Nie.  
    In ACM SIGIR 2020 (full paper). [![Paper](https://img.shields.io/badge/Paper-PDF-b31b1b)](http://haokunwen.github.io/files/acmsigir2020.pdf) [[Code]](https://joeyangbuer.wixsite.com/amgan) [[BibTex]](https://dblp.org/rec/conf/sigir/YangSHWNN20.html?view=bibtex)  
    




